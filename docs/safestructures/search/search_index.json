{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"safestructures","text":""},{"location":"#what-is-safestructures","title":"What is safestructures?","text":"<p><code>safestructures</code> is a Python package based on <code>safetensors</code> to serialize general data structures. It uses <code>safetensors</code> to store tensors and uses its metadata to store the schema of the original data structure as well as other basic data types.</p> <p><code>safetensors</code> can be more preferred than <code>pickle</code> when saving tensors, especially for safety reasons. See huggingface/safetensors for more details.</p> <p><code>safetensors</code> only stores tensors. <code>safestructures</code> extends <code>safetensors</code> by storing information of the original data structure containing tensors as well as other data types. It utilizes a plugin architecture so that projects that contain custom types can serialize and deserialize their custom data.</p>"},{"location":"#why-safestructures","title":"Why safestructures?","text":"<p>ML models in practice deal with more than just tensors. Tensors can be passed between layers or outputted using data containers. Other data types are used as well to modify layer behavior.</p> <p>To have better reproducibility and tracking, we may need to store and load model inputs and outputs, as well as intermediate layer inputs and output in a safe manner. <code>safetensors</code> greatly helps on the tensor side, while <code>safestructures</code> helps with the rest.</p>"},{"location":"#support","title":"Support","text":"<p>Currently, <code>safestructures</code> supports out of the box:</p> <ul> <li>All of Python's built-in data containers and data types.</li> <li><code>dataclasses.dataclass</code> objects.</li> <li>PyTorch tensors via <code>safetensors</code>.</li> <li>TensorFlow 2 tensors via <code>safetensors</code>.</li> <li>JAX tensors via <code>safetensors</code>.</li> </ul> <p>For maximum compatibility with NumPy, all float tensors are stored in FP32.</p> <p><code>safestructures</code> aims to cover the same frameworks as <code>safetensors</code>, but for initial release it does not support:</p> <ul> <li><code>collections</code> - Please comment on this issue to request support.</li> <li>PaddlePaddle - Please comment on this issue to request support.</li> <li>MLX - Please comment on this issue to request support.</li> </ul> <p>However, <code>safestructures</code> supports plugins in case there is a type it does not support.</p>"},{"location":"examples/","title":"Examples","text":"<p>The examples here use forward hooks to record layer inputs and outputs. They subclass <code>IOHook</code> below to save inputs and outputs.</p> <pre><code>from pathlib import PosixPath, Path\n\nfrom safestructures import save_file\n\nclass IOHook:\n    framework: str\n\n    def __init__(self, layer_name: str, save_dir: PosixPath):\n        self.layer_name = layer_name\n        self.save_dir = save_dir\n\n    def __call__(self, module, inputs, outputs):\n        input_filename = f\"{self.layer_name}_inputs_{self.times_called}.safestructures\"\n        output_filename = f\"{self.layer_name}_outputs_{self.times_called}.safestructures\"\n        input_save_file = self.save_dir / input_filename\n        output_save_file = self.save_dir / output_filename\n        save_file(inputs, input_save_file)\n        save_file(outputs, output_save_file)\n</code></pre>"},{"location":"examples/#pytorch-intermediate-input-and-outputs","title":"PyTorch intermediate input and outputs","text":"<pre><code>import torch\nfrom torchvision.models.resnet import resnet50, ResNet50_Weights\n\n\nclass TorchIOHook(IOHook):\n    framework = \"pt\"\n\nsave_dir = Path(\".\").expanduser().resolve()\n\nmodel = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\nmodel.eval()\n\nfor n, m in model.named_modules():\n    layer_name = n if n else \"model\"\n\n    io_hook = TorchIOHook(layer_name, save_dir)\n    m.register_forward_hook(io_hook)\n\ntest_input = torch.randn(8, 3, 224, 224)\n\nwith torch.no_grad():\n    model(test_input)\n</code></pre> <p>This would save all inputs seen and outputs generated by all layers.</p>"},{"location":"examples/#tensorflow-intermediate-input-and-outputs","title":"TensorFlow intermediate input and outputs","text":"<p>Note</p> <p>This uses tensorflow-hooks.</p> <pre><code>import tensorflow as tf\nfrom tf_hooks import register_forward_hook\n\nclass TFIOHook(IOHook):\n    framework = \"tf\"\n\n    def __call__(self, layer, args, kwargs, outputs):\n        # No kwargs for this example\n        super().__call__(layer, args, outputs)\n        return\n\nsave_dir = Path(\".\").expanduser().resolve()\n\nmodel = tf.keras.applications.ResNet50(weights=\"imagenet\")\n\nfor layer in model.layers:\n    io_hook = TFIOHook(layer.name, save_dir)\n    register_forward_hook(layer, io_hook)\n\ntest_input = tf.random.uniform((8, 224, 224, 3), maxval=1)\nmodel(test_input)\n</code></pre> <p>This would save all inputs seen and outputs generated by all layers.</p>"},{"location":"installation/","title":"Installation and Requirements","text":"<p><code>safestructures</code> requires Python 3.10 and above.</p> <p>To install, simply run <pre><code>pip install safestructures\n</code></pre> This will also install the minimum dependencies, namely <code>safetensors</code> and <code>numpy</code>.</p> <p>As for ML / tensor frameworks, <code>safestructures</code> expects <code>numpy</code> at minimum. To use <code>safestructures</code>'s PyTorch, TensorFlow, and JAX capabilities, the respective framework must be installed separately.</p>"},{"location":"license/","title":"License","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright 2024-2025 Craig Chan</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"plugins_guide/","title":"Plugins","text":"<p>WARNING</p> <p>The usage of plugins can execute arbitrary code. Be careful using plugins from a 3rd party.</p> <p><code>safestructures</code> utilizes a plugin-based architecture to process different data types. These are based on two main classes: <code>safestructures.DataProcessor</code> and <code>safestructures.TensorProcessor</code>.</p> <p><code>DataProcessor</code> serves as an abstract base class that you can extend to handle serialization and deserialization of specific data types. By subclassing <code>DataProcessor</code>, you can define how your custom data type is converted into a format that <code>safetensors</code> can store, and how to load it from <code>safetensors</code> metadata. This is subclassed directly for basic data types and data containers.</p> <p><code>TensorProcessor</code> is a special subclass of <code>DataProcessor</code>, utilizing <code>safetensors</code>'s capabilities to serialize and deserialize tensors.</p>"},{"location":"plugins_guide/#basic-types","title":"Basic types","text":"<p>Basic types, such as <code>str</code>, <code>int</code>, <code>float</code>, etc. use subclasses of <code>DataProcessor</code>. These are considered as \"atomic\" data types, the base case where no further serialization is needed. If you have a custom atomic data type, especially one that is not covered by core <code>safestructures</code> capabilities, then you would subclass <code>DataProcessor</code> (called <code>MyTypeProcessor</code> below for example) and follow 3 main steps:</p> <ol> <li>Define <code>MyTypeProcessor.data_type</code>, a class attribute.</li> <li>Implement <code>MyTypeProcessor.serialize</code>, the serialization method.<ul> <li>Input: A value of your custom type.</li> <li>Returns: A string. Strings are required to be compatible with <code>safetensors</code> metadata.</li> </ul> </li> <li>Implement <code>MyTypeProcessor.deserialize</code>, the deserialization method.<ul> <li>Input: The string representation of the value.</li> <li>Returns: the original value as your custom type.</li> </ul> </li> </ol> <p>For example, for the custom class: <pre><code>class MyCustomType:\n    def __init__(self, value: int):\n        self.value = value\n</code></pre></p> <p>The data processor would be: <pre><code>from safestructures import DataProcessor\n\nclass MyTypeProcessor(DataProcessor):\n    data_type = MyCustomType  # Set this to your custom data type\n\n    def serialize(self, data: MyCustomType) -&gt; str:\n        # Convert MyCustomType to a format Safetensors can store\n        return str(data.value)\n\n    def deserialize(self, serialized: str) -&gt; MyCustomType:\n        # Reconstruct MyCustomType from the serialized form\n        return MyCustomType(int(serialized))\n</code></pre></p> <p>You can then serialize your object or a data container containing your object by using the <code>plugins</code> keyword argument with <code>save_file</code> and <code>load_file</code>:</p> <pre><code>from safestructures import save_file, load_file\n\nlist_obj = [MyCustomType(42), MyCustomType(88)]\nfile_path = \"my_custom_objs.safestructures\"\n\nsave_file(list_obj, file_path, plugins=[MyTypeProcessor])\n\nloaded_obj = load_file(file_path, plugins=[MyTypeProcessor])\n</code></pre> <p>However, if the custom object you want to serialize is a container or even a nested container that would house atomic data types, then see the Containers section.</p>"},{"location":"plugins_guide/#optional-storing-other-metadata-to-aid-in-deserialization","title":"Optional: storing other metadata to aid in deserialization","text":"<p>It may be helpful to store other data that cannot be captured in a single string representation by <code>DataProcessor.serialize</code>, but would be needed to properly deserialize your custom data type. <code>DataProcessor.serialize_extra</code> helps with this by giving the option to provide extra metadata.</p> <p>It accepts the value you want to serialize, and your implementation would need to return a dictionary of only string types to be used as keyword arguments for <code>MyTypeProcessor.deserialize</code>. Note that <code>MyTypeProcessor.deserialize</code> would need to accept these keyword arguments.</p> <p>An example would be the core <code>DictProcessor</code>: </p> Source code in <code>src/safestructures/processors/iterable.py</code> <pre><code>class DictProcessor(DataProcessor):\n    \"\"\"Processor for dictionary data.\"\"\"\n\n    data_type = dict\n\n    def serialize(self, data: dict) -&gt; dict:\n        \"\"\"Overload `DataProcessor.serialize`.\"\"\"\n        results = {}\n        for k, v in data.items():\n            key = str(k)\n            results[key] = self.serializer.serialize(v)\n\n        return results\n\n    def serialize_extra(self, data: dict) -&gt; dict:\n        \"\"\"Overload `DataProcessor.serialize_extra`.\n\n        The additional schema to provide helps serialize\n        the dictionary keys themselves.\n        \"\"\"\n        # Keys can be numerical or tuple, not just strings.\n        schema = {KEYS_FIELD: {}}\n        for k in data:\n            key = str(k)\n            schema[KEYS_FIELD][key] = self.serializer.serialize(k)\n        return schema\n\n    def deserialize(self, serialized: dict, **kwargs) -&gt; dict:\n        \"\"\"Overload `DataProcessor.deserialize`.\"\"\"\n        results = {}\n        key_schemas = kwargs[KEYS_FIELD]\n        for k, v in serialized.items():\n            key_schema = key_schemas[k]\n            key = self.serializer.deserialize(key_schema)\n            results[key] = self.serializer.deserialize(v)\n\n        return results\n</code></pre> <p>Note</p> <p><code>DictProcessor</code> is a container plugin. See the Containers section for details on container plugins.</p>"},{"location":"plugins_guide/#tensors","title":"Tensors","text":"<p><code>TensorProcessor</code> is a special <code>DataProcessor</code>. The <code>serialize</code> and <code>deserialize</code> methods do not need to be overloaded for a subclass / plugin, but there are still 2 main steps:</p> <ol> <li>Define <code>MyTensorProcessor.data_type</code>, a class attribute.<ul> <li>This would be the tensor class of the ML framework.</li> </ul> </li> <li>Implement <code>MyTensorProcessor.to_numpy</code>, a processing method to convert to NumPy.<ul> <li>Input: The ML framework tensor.</li> <li>Returns: The tensor as a <code>numpy.ndarray</code>. The implementation should:<ul> <li>Provide a contiguous array.</li> <li>Be casted to FP32 for float tensors for maximum compatibility.</li> </ul> </li> </ul> </li> </ol> <p>An example would be the core <code>TorchProcessor</code>: </p> Source code in <code>src/safestructures/processors/tensor.py</code> <pre><code>class TorchProcessor(TensorProcessor):\n    \"\"\"PyTorch tensor processor.\"\"\"\n\n    data_type = torch.Tensor\n\n    def to_numpy(self, tensor: torch.Tensor) -&gt; np.ndarray:\n        \"\"\"Overload `TensorProcessor.to_numpy`.\"\"\"\n        tensor = tensor.detach().contiguous()\n        if torch.is_floating_point(tensor):\n            tensor = tensor.float()\n\n        return tensor.numpy()\n</code></pre>"},{"location":"plugins_guide/#containers","title":"Containers","text":"<p>Processors for containers such as lists and dictionaries are still <code>DataProcessor</code> subclasses but are recursive in nature. <code>safestructures</code> uses recursion to traverse a data structure. Unless there are values that are needed to be serialized at the container level, such as dictionary keys, no actual values are serialized/deserialized once the container object is reached. A <code>DataProcessor</code> for a container merely iterates through the object and uses <code>self.serializer.serialize</code> or <code>self.serializer.deserialize</code> to further serialize or deserialize child values, respectively.</p> <p>Implementing a <code>DataProcessor</code> subclass to handle your custom container class follows the same steps as for basic types, but with the following extra considerations:</p> <ol> <li>The <code>DataProcessor.serialize</code> method must use <code>self.serializer.serialize</code> to further serialize as you iterate through the values in the container.<ul> <li>Input: The data container to serialize.</li> <li>Output: Must be a <code>builtin</code> container. Consider what <code>builtin</code> container (such as <code>dict</code> or <code>list</code>) best fits your custom container class. For example, <code>safestructures</code> uses <code>dict</code> to help serialize <code>dataclasses.dataclass</code> objects.</li> </ul> </li> <li>The <code>DataProcessor.deserialize</code> method must use <code>self.serializer.deserialize</code> to further deserialize as you iterate through the values in a <code>builtin</code> serialized container.<ul> <li>Input: A <code>builtin</code> container with serialized values. For example, an object that used a dictionary to serialize would have a <code>dict</code> provided to <code>DataProcessor.deserialize</code>, and a list/tuple/set-like object would have a <code>list</code> provided to <code>DataProcessor.deserialize</code>.</li> <li>Output: The deserialized custom object.</li> </ul> </li> </ol> <p>The <code>DictProcessor</code> implementation above is a good example of these concepts, while also exercising <code>DataProcessor.serialize_extra</code> to handle other values that require serialization at the container level.</p> <p>In <code>safestructures</code>, the core container processors are iterable in nature, so all are in the <code>safestructures.processor.iterable</code> submodule:</p> <ul> <li><code>ListProcessor</code></li> <li><code>SetProcessor</code></li> <li><code>TupleProcessor</code></li> <li><code>DictProcessor</code></li> <li><code>DataclassProcessor</code></li> </ul> <p>For example, let's create a plugin for <code>transformers.modeling_outputs.ModelOutput</code> objects. Since <code>ModelOutput</code> objects are similar to <code>dataclasses.dataclass</code> objects, we'll subclass <code>safestructures.processors.iterable.DataclassProcessor</code></p> <pre><code>from safestructures.processors.iterable import DataclassProcessor\n\nclass ModelOutputProcessor(DataclassProcessor):\n    \"\"\"Processor for `transformers`'s ModelOutput.\"\"\"\n\n    data_type = ModelOutput\n\n    def deserialize(self, serialized: dict, **kwargs) -&gt; ModelOutput:\n        \"\"\"Overload DataclassProcessor.deserialize.\n\n        This is so the proper ModelOutput is provided.\n        \"\"\"\n        mo_kwargs = {}\n        for k, v in serialized.items():\n            mo_kwargs[k] = self.serializer.deserialize(v)\n\n        model_output_instance = self.data_type(**mo_kwargs)\n\n        return model_output_instance\n</code></pre> <p>Since most <code>ModelOutput</code> objects from a <code>transformers</code> model are subclasses, we can just subclass <code>ModelOutputProcessor</code> like below: <pre><code>from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions BaseModelOutputWithPoolingAndCrossAttentions\n\nclass BertOutputProcessor(ModelOutputProcessor):\n    \"\"\"Processor for BERT model outputs.\"\"\"\n\n    data_type = BaseModelOutputWithPoolingAndCrossAttentions\n\n\nclass BertEncoderOutputProcessor(ModelOutputProcessor):\n    \"\"\"Processor for BERT encoder outputs.\"\"\"\n\n    data_type = BaseModelOutputWithPastAndCrossAttentions\n</code></pre></p> <p>We can then serialize outputs of the model. Below is a PyTorch-based example: <pre><code>from transformers import BertConfig, BertModel\n\nconfig = BertConfig()\nmodel = BertModel(config)\ntest_plugins = [BertOutputProcessor, BertEncoderOutputProcessor]\n\nresults = {}\n\ndef _store_encoder_output(module, args, kwargs, output):\n    results[\"encoder_output\"] = output\n    return output\n\nmodel.encoder.register_forward_hook(_store_encoder_output, with_kwargs=True)\n\ntest_input_ids = torch.tensor([[0] * 128])\ntest_output = model(test_input_ids)\n\nresults[\"model_output\"] = test_output\n\ntest_filepath = tmp_path / \"test.safestructures\"\nsave_file(results, test_filepath, plugins=test_plugins)\n\ndeserialized = load_file(test_filepath, plugins=test_plugins)\n</code></pre></p>"},{"location":"usage/","title":"Usage","text":"<p>To use the core functionalities of <code>safestructures</code>, only two functions are needed: <code>save_file</code> and <code>load_file</code>.</p>"},{"location":"usage/#saving-serializing","title":"Saving / serializing","text":"<p>To save a Python object, simply use:</p> <pre><code>from safestructures import save_file\n\ndata: Object = None # any value or data container\nsave_path = \"path/to/save/obj.safestructures\"\n\nsave_file(data, save_path)\n</code></pre> <p>Note about Dataclasses</p> <p><code>safestructures</code> treats <code>dataclass</code> objects as a special case. The original class will be used when deserializing, but by default a dataclass specific to <code>safestructures</code> will be used restore the object unless a plugin is used.</p> <p>Go here to see more examples.</p>"},{"location":"usage/#saving-additional-metadata","title":"Saving additional metadata","text":"<p>Metadata can be saved using the <code>metadata</code> keyword argument with <code>save_file</code>. It accepts a flattened dictionary of key type <code>str</code>, value type <code>str</code>, as that is what <code>safetensors</code> accepts.</p> <p>To load metadata, load as you would with a normal <code>safetensors</code> file, namely:</p> <pre><code>from safetensors import safe_open\n\nfile_path = \"path/to/load/obj.safestructures\"\n\nwith safe_open(load_path) as f:\n    metadata = f.metadata()\n</code></pre>"},{"location":"usage/#loading-deserializing","title":"Loading / deserializing","text":"<p>To load a Python object, simply use:</p> <pre><code>from safestructures import save_file\n\nfile_path = \"path/to/load/obj.safestructures\"\n\nobj = load_file(file_path)\n</code></pre> <p><code>obj</code> will be the object saved from <code>save_file</code>.</p> <p>Go here to see more examples.</p>"},{"location":"usage/#what-if-safestructures-does-not-handle-a-certain-type","title":"What if <code>safestructures</code> does not handle a certain type?","text":"<p><code>safestructures</code> is extensible through plugins. See plugins for more details.</p>"},{"location":"api/dataprocessor/","title":"safestructures.DataProcessor","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for data processors other than tensors.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>class DataProcessor(ABC):\n    \"\"\"Base class for data processors other than tensors.\"\"\"\n\n    data_type: Type[Any] = Any\n\n    def __init__(self, serializer: Serializer):\n        \"\"\"Initialize the DataProcessor.\n\n        Args:\n            serializer (Serializer): The serializer.\n                This may be used to help recursively process.\n        \"\"\"\n        self.serializer = serializer\n\n    @property\n    def schema_type(self) -&gt; str:\n        \"\"\"Provide the data type in schema-compatible format.\n\n        Returns:\n            str: The import path of the data type.\n        \"\"\"\n        return get_import_path(self.data_type)\n\n    @abstractmethod\n    def serialize(self, data: Any) -&gt; Union[str, None, bool, list, dict]:\n        \"\"\"Serialize the data.\n\n        Args:\n            data (Any): The data to serialize.\n\n        Returns:\n            Union[str, None, bool, list, dict]: The serialized value.\n                Safetensors only accepts strings in the metadata.\n                json.dumps is used, so None and booleans are handled.\n                Lists and dictionaries of accepted data types as indicated\n                here are acceptable, including nested types.\n        \"\"\"\n        pass\n\n    def serialize_extra(self, data: Any) -&gt; dict:\n        \"\"\"Provide extra serialization details to the schema.\n\n        Args:\n            data (Any): The data to generate additional schema.\n\n        Returns:\n            dict: The additional schema to add onto the data's schema.\n                The keys must not conflict with TYPE_FIELD and VALUE_FIELD,\n                and must be strings.\n                The values must also be of acceptable type to Safetensors metadata.\n                See `DataProcessor.serialize`\n        \"\"\"\n        return {}\n\n    @abstractmethod\n    def deserialize(\n        self, serialized: Union[str, None, bool, list, dict], **kwargs\n    ) -&gt; Any:\n        \"\"\"Deserialize the schema into data.\n\n        Args:\n            schema (Any): The serialized value.\n\n        Any additional schema other than VALUE_FIELD will be\n        passed as keyword arguments.\n\n        Returns:\n            Any: The loaded value.\n        \"\"\"\n        pass\n\n    def __call__(self, data_or_schema: Any) -&gt; Any:\n        \"\"\"Process the data or schema.\n\n        Args:\n            data_or_schema (Any): The data (Any) or schema (dict).\n\n        Returns:\n            The schema if the serializer is in save mode,\n            The loaded data if the serializer is in load mode.\n        \"\"\"\n        mode = self.serializer.mode\n        if mode == Mode.SAVE:\n            schema = {TYPE_FIELD: self.schema_type}\n\n            schema[VALUE_FIELD] = self.serialize(data_or_schema)\n            extra = self.serialize_extra(data_or_schema)\n\n            if not isinstance(extra, dict):\n                raise TypeError(\n                    f\"{type(self)}.serialize_extra must return a dictionary.\"\n                )\n            if TYPE_FIELD in extra:\n                raise KeyError(\n                    f\"{type(self)}.serialize_extra must not have a {TYPE_FIELD} key.\"\n                )\n            if VALUE_FIELD in extra:\n                raise KeyError(\n                    f\"{type(self)}.serialize_extra must not have a {VALUE_FIELD} key.\"\n                )\n\n            for k in extra.keys():\n                if not isinstance(k, str):\n                    raise TypeError(\n                        (\n                            f\"Dictionary returned by {type(self)}.serialize_extra\"\n                            \" must have string keys only.\"\n                        )\n                    )\n            schema.update(extra)\n\n            return schema\n\n        elif mode == Mode.LOAD:\n            kwargs = {}\n            for k in data_or_schema:\n                if k not in [TYPE_FIELD, VALUE_FIELD]:\n                    kwargs[k] = data_or_schema[k]\n            return self.deserialize(data_or_schema[VALUE_FIELD], **kwargs)\n\n        else:\n            raise ValueError(f\"Mode {mode} not recognized.\")\n</code></pre>"},{"location":"api/dataprocessor/#safestructures.DataProcessor.schema_type","title":"<code>schema_type</code>  <code>property</code>","text":"<p>Provide the data type in schema-compatible format.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The import path of the data type.</p>"},{"location":"api/dataprocessor/#safestructures.DataProcessor.__call__","title":"<code>__call__(data_or_schema)</code>","text":"<p>Process the data or schema.</p> <p>Parameters:</p> Name Type Description Default <code>data_or_schema</code> <code>Any</code> <p>The data (Any) or schema (dict).</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The schema if the serializer is in save mode,</p> <code>Any</code> <p>The loaded data if the serializer is in load mode.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>def __call__(self, data_or_schema: Any) -&gt; Any:\n    \"\"\"Process the data or schema.\n\n    Args:\n        data_or_schema (Any): The data (Any) or schema (dict).\n\n    Returns:\n        The schema if the serializer is in save mode,\n        The loaded data if the serializer is in load mode.\n    \"\"\"\n    mode = self.serializer.mode\n    if mode == Mode.SAVE:\n        schema = {TYPE_FIELD: self.schema_type}\n\n        schema[VALUE_FIELD] = self.serialize(data_or_schema)\n        extra = self.serialize_extra(data_or_schema)\n\n        if not isinstance(extra, dict):\n            raise TypeError(\n                f\"{type(self)}.serialize_extra must return a dictionary.\"\n            )\n        if TYPE_FIELD in extra:\n            raise KeyError(\n                f\"{type(self)}.serialize_extra must not have a {TYPE_FIELD} key.\"\n            )\n        if VALUE_FIELD in extra:\n            raise KeyError(\n                f\"{type(self)}.serialize_extra must not have a {VALUE_FIELD} key.\"\n            )\n\n        for k in extra.keys():\n            if not isinstance(k, str):\n                raise TypeError(\n                    (\n                        f\"Dictionary returned by {type(self)}.serialize_extra\"\n                        \" must have string keys only.\"\n                    )\n                )\n        schema.update(extra)\n\n        return schema\n\n    elif mode == Mode.LOAD:\n        kwargs = {}\n        for k in data_or_schema:\n            if k not in [TYPE_FIELD, VALUE_FIELD]:\n                kwargs[k] = data_or_schema[k]\n        return self.deserialize(data_or_schema[VALUE_FIELD], **kwargs)\n\n    else:\n        raise ValueError(f\"Mode {mode} not recognized.\")\n</code></pre>"},{"location":"api/dataprocessor/#safestructures.DataProcessor.__init__","title":"<code>__init__(serializer)</code>","text":"<p>Initialize the DataProcessor.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>Serializer</code> <p>The serializer. This may be used to help recursively process.</p> required Source code in <code>src/safestructures/processors/base.py</code> <pre><code>def __init__(self, serializer: Serializer):\n    \"\"\"Initialize the DataProcessor.\n\n    Args:\n        serializer (Serializer): The serializer.\n            This may be used to help recursively process.\n    \"\"\"\n    self.serializer = serializer\n</code></pre>"},{"location":"api/dataprocessor/#safestructures.DataProcessor.deserialize","title":"<code>deserialize(serialized, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Deserialize the schema into data.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Any</code> <p>The serialized value.</p> required <p>Any additional schema other than VALUE_FIELD will be passed as keyword arguments.</p> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The loaded value.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>@abstractmethod\ndef deserialize(\n    self, serialized: Union[str, None, bool, list, dict], **kwargs\n) -&gt; Any:\n    \"\"\"Deserialize the schema into data.\n\n    Args:\n        schema (Any): The serialized value.\n\n    Any additional schema other than VALUE_FIELD will be\n    passed as keyword arguments.\n\n    Returns:\n        Any: The loaded value.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/dataprocessor/#safestructures.DataProcessor.serialize","title":"<code>serialize(data)</code>  <code>abstractmethod</code>","text":"<p>Serialize the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to serialize.</p> required <p>Returns:</p> Type Description <code>Union[str, None, bool, list, dict]</code> <p>Union[str, None, bool, list, dict]: The serialized value. Safetensors only accepts strings in the metadata. json.dumps is used, so None and booleans are handled. Lists and dictionaries of accepted data types as indicated here are acceptable, including nested types.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>@abstractmethod\ndef serialize(self, data: Any) -&gt; Union[str, None, bool, list, dict]:\n    \"\"\"Serialize the data.\n\n    Args:\n        data (Any): The data to serialize.\n\n    Returns:\n        Union[str, None, bool, list, dict]: The serialized value.\n            Safetensors only accepts strings in the metadata.\n            json.dumps is used, so None and booleans are handled.\n            Lists and dictionaries of accepted data types as indicated\n            here are acceptable, including nested types.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/dataprocessor/#safestructures.DataProcessor.serialize_extra","title":"<code>serialize_extra(data)</code>","text":"<p>Provide extra serialization details to the schema.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to generate additional schema.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The additional schema to add onto the data's schema. The keys must not conflict with TYPE_FIELD and VALUE_FIELD, and must be strings. The values must also be of acceptable type to Safetensors metadata. See <code>DataProcessor.serialize</code></p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>def serialize_extra(self, data: Any) -&gt; dict:\n    \"\"\"Provide extra serialization details to the schema.\n\n    Args:\n        data (Any): The data to generate additional schema.\n\n    Returns:\n        dict: The additional schema to add onto the data's schema.\n            The keys must not conflict with TYPE_FIELD and VALUE_FIELD,\n            and must be strings.\n            The values must also be of acceptable type to Safetensors metadata.\n            See `DataProcessor.serialize`\n    \"\"\"\n    return {}\n</code></pre>"},{"location":"api/load_file/","title":"safestructures.load_file","text":"<p>Load data using Safestructures.</p> <p>The file must be a valid Safestructures file, i.e Safetensors file with additional Safestructures metadata.</p> <p>Parameters:</p> Name Type Description Default <code>load_path</code> <code>Union[str, PosixPath]</code> <p>Path to a valid Safestructures file.</p> required <code>framework</code> <code>str</code> <p>The framework to load tensors into. Defaults to \"np\" for Numpy.</p> <code>'np'</code> <code>device</code> <code>str</code> <p>Device to allocate tensors to. Defaults to \"cpu\" to allocate on CPU.</p> <code>'cpu'</code> <code>plugins</code> <code>Optional[Union[PROCESSOR_TYPES, list[PROCESSOR_TYPES]]]</code> <p>Additional plugins to serialize data for data types not covered by safestructures. Defaults to None for no plugins.</p> <code>None</code> <p>Returns:</p> Type Description <p>The loaded data.</p> Source code in <code>src/safestructures/wrapper.py</code> <pre><code>def load_file(\n    load_path: Union[str, PosixPath],\n    framework: str = \"np\",\n    device: str = \"cpu\",\n    plugins: Optional[Union[PROCESSOR_TYPES, list[PROCESSOR_TYPES]]] = None,\n):\n    \"\"\"Load data using Safestructures.\n\n    The file must be a valid Safestructures file,\n    i.e Safetensors file with additional Safestructures metadata.\n\n    Args:\n        load_path (Union[str, PosixPath]): Path to a valid Safestructures file.\n        framework (str, optional): The framework to load tensors into.\n            Defaults to \"np\" for Numpy.\n        device (str, optional): Device to allocate tensors to.\n            Defaults to \"cpu\" to allocate on CPU.\n        plugins (Optional[Union[PROCESSOR_TYPES, list[PROCESSOR_TYPES]]], optional):\n            Additional plugins to serialize data for data types not covered\n            by safestructures. Defaults to None for no plugins.\n\n    Returns:\n        The loaded data.\n    \"\"\"\n    if plugins and not isinstance(plugins, list):\n        plugins = [plugins]\n\n    return Serializer(plugins=plugins).load(\n        load_path, framework=framework, device=device\n    )\n</code></pre>"},{"location":"api/save_file/","title":"safestructures.save_file","text":"<p>Save data using Safestructures.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>Data to save. Data must use data types that are serializable by Safetensors/Safestructures.</p> required <code>save_path</code> <code>Union[str, PosixPath]</code> <p>Path to save the data. Directory must already exist.</p> required <code>metadata</code> <code>Optional[dict[str, str]]</code> <p>Additional metadata to save. Defaults to None for no metadata.</p> <code>None</code> <code>plugins</code> <code>Optional[Union[PROCESSOR_TYPES, list[PROCESSOR_TYPES]]]</code> <p>Additional plugins to serialize data for data types not covered by safestructures. Defaults to None for no plugins.</p> <code>None</code> <p>Returns:</p> Type Description <p>None.</p> Source code in <code>src/safestructures/wrapper.py</code> <pre><code>def save_file(\n    data: Any,\n    save_path: Union[str, PosixPath],\n    metadata: Optional[dict[str, str]] = None,\n    plugins: Optional[Union[PROCESSOR_TYPES, list[PROCESSOR_TYPES]]] = None,\n):\n    \"\"\"Save data using Safestructures.\n\n    Args:\n        data (Any): Data to save.\n            Data must use data types that are serializable\n            by Safetensors/Safestructures.\n        save_path (Union[str, PosixPath]): Path to save the data.\n            Directory must already exist.\n        metadata (Optional[dict[str, str]], optional): Additional metadata to save.\n            Defaults to None for no metadata.\n        plugins (Optional[Union[PROCESSOR_TYPES, list[PROCESSOR_TYPES]]], optional):\n            Additional plugins to serialize data for data types not covered\n            by safestructures. Defaults to None for no plugins.\n\n    Returns:\n        None.\n    \"\"\"\n    if plugins and not isinstance(plugins, list):\n        plugins = [plugins]\n\n    return Serializer(plugins=plugins).save(data, save_path, metadata=metadata)\n</code></pre>"},{"location":"api/tensorprocessor/","title":"safestructures.TensorProcessor","text":"<p>               Bases: <code>DataProcessor</code>, <code>ABC</code></p> <p>Base class to process tensors.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>class TensorProcessor(DataProcessor, ABC):\n    \"\"\"Base class to process tensors.\"\"\"\n\n    @abstractmethod\n    def to_numpy(self, tensor: Any) -&gt; np.ndarray:\n        \"\"\"Convert tensor to Numpy array.\n\n        Args:\n            tensor (Any): The tensor to convert to Numpy.\n\n        Returns:\n            np.ndarray: The tensor as a Numpy array.\n        \"\"\"\n        pass\n\n    def process_tensor(self, tensor: np.ndarray) -&gt; str:\n        \"\"\"Process a tensor for serialization.\n\n        Args:\n            tensor (np.ndarray): The tensor as Numpy array.\n\n        Returns:\n            str: The tensor ID.\n        \"\"\"\n        assert isinstance(tensor, np.ndarray), \"Tensor must be np.ndarry at this point.\"\n        _id = str(len(self.serializer.tensors))\n        self.serializer.tensors[_id] = tensor\n        return _id\n\n    def serialize(self, tensor: Any) -&gt; dict:\n        \"\"\"Overload `DataProcessor.serialize`.\"\"\"\n        tensor = self.to_numpy(tensor)\n        return self.process_tensor(tensor)\n\n    def deserialize(self, tensor_id: str, **kwargs) -&gt; Any:\n        \"\"\"Overload `DataProcessor.deserialize`.\"\"\"\n        return self.serializer.tensors[tensor_id]\n</code></pre>"},{"location":"api/tensorprocessor/#safestructures.TensorProcessor.deserialize","title":"<code>deserialize(tensor_id, **kwargs)</code>","text":"<p>Overload <code>DataProcessor.deserialize</code>.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>def deserialize(self, tensor_id: str, **kwargs) -&gt; Any:\n    \"\"\"Overload `DataProcessor.deserialize`.\"\"\"\n    return self.serializer.tensors[tensor_id]\n</code></pre>"},{"location":"api/tensorprocessor/#safestructures.TensorProcessor.process_tensor","title":"<code>process_tensor(tensor)</code>","text":"<p>Process a tensor for serialization.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>ndarray</code> <p>The tensor as Numpy array.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The tensor ID.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>def process_tensor(self, tensor: np.ndarray) -&gt; str:\n    \"\"\"Process a tensor for serialization.\n\n    Args:\n        tensor (np.ndarray): The tensor as Numpy array.\n\n    Returns:\n        str: The tensor ID.\n    \"\"\"\n    assert isinstance(tensor, np.ndarray), \"Tensor must be np.ndarry at this point.\"\n    _id = str(len(self.serializer.tensors))\n    self.serializer.tensors[_id] = tensor\n    return _id\n</code></pre>"},{"location":"api/tensorprocessor/#safestructures.TensorProcessor.serialize","title":"<code>serialize(tensor)</code>","text":"<p>Overload <code>DataProcessor.serialize</code>.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>def serialize(self, tensor: Any) -&gt; dict:\n    \"\"\"Overload `DataProcessor.serialize`.\"\"\"\n    tensor = self.to_numpy(tensor)\n    return self.process_tensor(tensor)\n</code></pre>"},{"location":"api/tensorprocessor/#safestructures.TensorProcessor.to_numpy","title":"<code>to_numpy(tensor)</code>  <code>abstractmethod</code>","text":"<p>Convert tensor to Numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Any</code> <p>The tensor to convert to Numpy.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The tensor as a Numpy array.</p> Source code in <code>src/safestructures/processors/base.py</code> <pre><code>@abstractmethod\ndef to_numpy(self, tensor: Any) -&gt; np.ndarray:\n    \"\"\"Convert tensor to Numpy array.\n\n    Args:\n        tensor (Any): The tensor to convert to Numpy.\n\n    Returns:\n        np.ndarray: The tensor as a Numpy array.\n    \"\"\"\n    pass\n</code></pre>"}]}